{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c71bed5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pickle\n",
    "np.random.seed(0)\n",
    "from scripts import (\n",
    "    #train_test_split,\n",
    "    StandardScaler,\n",
    "    accuracy,\n",
    "    confusion_matrix,\n",
    "    recall_per_class,\n",
    "    balanced_accuracy,\n",
    "    KernelPerceptron,\n",
    "    SVM,\n",
    "    rbf_kernel,\n",
    "    rbf_kernel_svm,\n",
    "    hybrid_kernel,\n",
    "    SoftmaxClassifier\n",
    ")\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "78515f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in training set: [486 128 206 194  66]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- Load training data ---\n",
    "path_to_data = 'ift-3395-6390-kaggle-2-competition-fall-2025/train_data.pkl'\n",
    "with open(path_to_data, \"rb\") as f:\n",
    "    train_data = pickle.load(f)\n",
    "\n",
    "X_imgs = train_data[\"images\"].astype(np.float32)\n",
    "y = train_data[\"labels\"].reshape(-1)\n",
    "\n",
    "class_count = np.bincount(y)\n",
    "print(\"Class distribution in training set:\", class_count)\n",
    "\n",
    "\n",
    "X_train_imgs, X_val_imgs, y_train, y_val = train_test_split(\n",
    "    X_imgs, y, test_size=0.2, random_state=0, stratify=y\n",
    ")\n",
    "\n",
    "train_min = X_train_imgs.min()\n",
    "train_max = X_train_imgs.max()\n",
    "\n",
    "train_mean = X_train_imgs.mean()\n",
    "train_std = X_train_imgs.std()\n",
    "\n",
    "X_train_imgs = (X_train_imgs - train_min) / (train_max - train_min + 1e-6)\n",
    "X_train_imgs = (X_train_imgs - train_mean) / (train_std + 1e-6)\n",
    "\n",
    "X_val_imgs = (X_val_imgs - train_min) / (train_max - train_min + 1e-6)\n",
    "X_val_imgs = (X_val_imgs - train_mean) / (train_std + 1e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e0991169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def radial_profile(img):\n",
    "    \"\"\"Calcule le profil radial moyen d'une image.\"\"\"\n",
    "    h, w = img.shape\n",
    "    y, x = np.ogrid[:h, :w]\n",
    "    r = np.sqrt((x - w//2)**2 + (y - h//2)**2).astype(int)\n",
    "    profile = np.bincount(r.ravel(), img.ravel()) / np.bincount(r.ravel())\n",
    "    return np.log(profile + 1e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "352f775f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_simple_stats(img):\n",
    "    gray = img.mean(axis=2)\n",
    "    return np.array([gray.mean(), gray.std(), gray.min(), gray.max()], dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b30b6d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_augment(images, labels):\n",
    "    flips = images[:, :, ::-1, :]  \n",
    "    noise = images + 0.01*np.random.randn(*images.shape)\n",
    "    aug_imgs = np.concatenate([images, flips, noise], axis=0)\n",
    "    aug_labels = np.concatenate([labels, labels, labels])\n",
    "    return aug_imgs, aug_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "4bb9c341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_channel_stats(img):\n",
    "    # img.shape est (H, W, 3)\n",
    "    features = []\n",
    "    for c in range(img.shape[2]): # Itere sur les 3 canaux\n",
    "        channel = img[:, :, c]\n",
    "        features.extend([channel.mean(), channel.std(), channel.min(), channel.max()])\n",
    "    return np.array(features, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c24996fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fft_features(images):\n",
    "    \"\"\"Extrait les caractéristiques FFT d'images.\"\"\"\n",
    "    gray = images.mean(axis=3)\n",
    "    F = np.fft.fft2(gray, axes=(1, 2))\n",
    "    return np.abs(np.fft.fftshift(F, axes=(1, 2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e74671b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve_2d_sobel(image, kernel):\n",
    "    k_h, k_w = kernel.shape\n",
    "    i_h, i_w = image.shape\n",
    "    pad_h, pad_w = k_h // 2, k_w // 2\n",
    "    \n",
    "    # Ajouter le padding (nécessaire pour Sobel)\n",
    "    padded_image = np.pad(image, ((pad_h, pad_h), (pad_w, pad_w)), mode='edge') # edge padding souvent mieux pour Sobel\n",
    "    output = np.zeros_like(image, dtype=np.float32)\n",
    "    \n",
    "    for i in range(i_h):\n",
    "        for j in range(i_w):\n",
    "            window = padded_image[i:i+k_h, j:j+k_w]\n",
    "            output[i, j] = np.sum(window * kernel)\n",
    "            \n",
    "    return output\n",
    "\n",
    "def extract_sobel_features(img):\n",
    "    # Canal Vert (indice 1) est souvent le meilleur pour les vaisseaux\n",
    "    green_channel = img[:, :, 1] \n",
    "    \n",
    "    Gx = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=np.float32)\n",
    "    Gy = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=np.float32)\n",
    "\n",
    "    Ix = convolve_2d_sobel(green_channel, Gx)\n",
    "    Iy = convolve_2d_sobel(green_channel, Gy)\n",
    "\n",
    "    # Magnitude du gradient (approximation simple: |Ix| + |Iy|)\n",
    "    # Utiliser np.sqrt(Ix**2 + Iy**2) est plus précis mais plus lent.\n",
    "    magnitude = np.abs(Ix) + np.abs(Iy) \n",
    "    \n",
    "    # Caractéristiques : Moyenne et écart-type de la magnitude\n",
    "    return np.array([magnitude.mean(), magnitude.std()], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "24077e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_hsv(img):\n",
    "    \"\"\"Convertit une image RGB (0-1.0) en HSV (H:0-360, S:0-1, V:0-1).\"\"\"\n",
    "    R, G, B = img[:, :, 0], img[:, :, 1], img[:, :, 2]\n",
    "    \n",
    "    # Valeur (V)\n",
    "    V = np.max(img, axis=2)\n",
    "    \n",
    "    # Min de R, G, B\n",
    "    M_min = np.min(img, axis=2)\n",
    "    \n",
    "    # Delta (pour éviter la division par zéro)\n",
    "    Delta = V - M_min\n",
    "    \n",
    "    # Saturation (S)\n",
    "    S = np.zeros_like(V)\n",
    "    # Masque pour les pixels où Delta > 0 (nécessaire pour la division)\n",
    "    mask = Delta > 1e-6 \n",
    "    S[mask] = Delta[mask] / V[mask]\n",
    "    \n",
    "    # Teinte (H)\n",
    "    H = np.zeros_like(V)\n",
    "    \n",
    "    # Préparation des masques spécifiques\n",
    "    R_is_max = (R == V) & mask\n",
    "    G_is_max = (G == V) & mask\n",
    "    B_is_max = (B == V) & mask\n",
    "\n",
    "    # Calcul de H pour chaque cas (utilisant la formule trigonométrique)\n",
    "    H[R_is_max] = 60 * (G[R_is_max] - B[R_is_max]) / Delta[R_is_max]\n",
    "    H[G_is_max] = 60 * (2.0 + (B[G_is_max] - R[G_is_max]) / Delta[G_is_max])\n",
    "    H[B_is_max] = 60 * (4.0 + (R[B_is_max] - G[B_is_max]) / Delta[B_is_max])\n",
    "    \n",
    "    # Correction des valeurs négatives pour H (H doit être entre 0 et 360)\n",
    "    H[H < 0] += 360\n",
    "    \n",
    "    # Empilement et retour (Normaliser H de 0-360 à 0-1.0 pour la cohérence)\n",
    "    H_norm = H / 360.0\n",
    "    \n",
    "    return np.stack([H_norm, S, V], axis=2)\n",
    "\n",
    "def extract_hsv_stats(img):\n",
    "    hsv_img = rgb_to_hsv(img)\n",
    "    features = []\n",
    "    \n",
    "    # Extraire les statistiques pour H (Teinte) et S (Saturation)\n",
    "    for c in range(2): # 0=H, 1=S\n",
    "        channel = hsv_img[:, :, c]\n",
    "        features.extend([channel.mean(), channel.std()]) # Moyenne et écart-type sont les plus utiles\n",
    "        \n",
    "    return np.array(features, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "98a8e377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_regional_stats(img):\n",
    "    # Utiliser le canal vert (indice 1) pour le contraste\n",
    "    green_channel = img[:, :, 1] \n",
    "    H, W = green_channel.shape\n",
    "    H_half, W_half = H // 2, W // 2\n",
    "    \n",
    "    # Quadrants (Q1: top-left, Q2: top-right, etc.)\n",
    "    Q1 = green_channel[:H_half, :W_half]\n",
    "    Q2 = green_channel[:H_half, W_half:]\n",
    "    Q3 = green_channel[H_half:, :W_half]\n",
    "    Q4 = green_channel[H_half:, W_half:]\n",
    "    \n",
    "    features = []\n",
    "    for Q in [Q1, Q2, Q3, Q4]:\n",
    "        # Ajouter la moyenne et l'écart-type de chaque quadrant\n",
    "        features.extend([Q.mean(), Q.std()])\n",
    "        \n",
    "    # Total : 4 quadrants * 2 stats = 8 caractéristiques\n",
    "    return np.array(features, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ef62ceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imgs, y_train = simple_augment(X_train_imgs, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "53f78d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_ff \n",
    "# Test accuracy = 0.35185185185185186\n",
    "# Balanced acc : 0.21607963740224237\n",
    "\n",
    "# X_stats\n",
    "#Test accuracy = 0.21296296296296297\n",
    "#Balanced acc : 0.21641103008968235\n",
    "\n",
    "# X_color\n",
    "#Test accuracy = 0.39351851851851855\n",
    "#Balanced acc : 0.26298782099637014\n",
    "\n",
    "\n",
    "# X_regional\n",
    "\n",
    "# Test accuracy = 0.3611111111111111\n",
    "# Balanced acc : 0.19380218306544683\n",
    "\n",
    "# X_sobel\n",
    "# Test accuracy = 0.3101851851851852\n",
    "# Balanced acc : 0.19615481325312858\n",
    "\n",
    "# X_hsv\n",
    "# Test accuracy = 0.35648148148148145\n",
    "# Balanced acc : 0.2990335454504426\n",
    "\n",
    "fft_mag_train = fft_features(X_train_imgs)\n",
    "X_fft_train = np.array([radial_profile(img) for img in fft_mag_train], dtype=np.float32)\n",
    "X_stats_train = np.array([extract_simple_stats(img) for img in X_train_imgs], dtype=np.float32)\n",
    "X_color_train = np.array([extract_channel_stats(img) for img in X_train_imgs], dtype=np.float32)\n",
    "X_sobel_train = np.array([extract_sobel_features(img) for img in X_train_imgs], dtype=np.float32)\n",
    "X_hsv_train = np.array([extract_hsv_stats(img) for img in X_train_imgs], dtype=np.float32)\n",
    "X_regional_train = np.array([extract_regional_stats(img) for img in X_train_imgs], dtype=np.float32)\n",
    "\n",
    "\n",
    "\n",
    "fft_mag_val = fft_features(X_val_imgs)\n",
    "X_fft_val = np.array([radial_profile(img) for img in fft_mag_val], dtype=np.float32)\n",
    "X_stats_val = np.array([extract_simple_stats(img) for img in X_val_imgs], dtype=np.float32)\n",
    "X_color_val = np.array([extract_channel_stats(img) for img in X_val_imgs], dtype=np.float32)\n",
    "X_sobel_val = np.array([extract_sobel_features(img) for img in X_val_imgs], dtype=np.float32)\n",
    "X_hsv_val = np.array([extract_hsv_stats(img) for img in X_val_imgs], dtype=np.float32)\n",
    "X_regional_val = np.array([extract_regional_stats(img) for img in X_val_imgs], dtype=np.float32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "60ae9558",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.hstack([\n",
    "                     X_fft_train,\n",
    "                     X_stats_train, \n",
    "                     X_color_train,\n",
    "                     ])\n",
    "\n",
    "X_val = np.hstack([\n",
    "                   X_fft_val, \n",
    "                   X_stats_val, \n",
    "                   X_color_val,\n",
    "                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "de2cd8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "53b40fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = np.bincount(y_val)\n",
    "class_weights = (1.0 / class_counts)\n",
    "class_weights /= class_weights.sum() \n",
    "sample_weights = class_weights[y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "8bd461e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier for class 0...\n",
      "Training classifier for class 1...\n",
      "Training classifier for class 2...\n",
      "Training classifier for class 3...\n",
      "Training classifier for class 4...\n",
      "Training done.\n"
     ]
    }
   ],
   "source": [
    "model = KernelPerceptron(kernel_fn=rbf_kernel, n_classes=5, sigma=1, learning_rate=1.0,  sample_weights=None, lam=0.0)\n",
    "\n",
    "model.fit(X_train, y_train, max_epochs=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de6ab64",
   "metadata": {},
   "source": [
    "Understanding Deep Learning Requires Rethinking Generalization\n",
    "(Zhang et al., ICLR 2017) → importance de la fréquence dans image classification.\n",
    "Fourier Transform in Image Processing — Gonzalez & Woods\n",
    "(exemples de séparation de classes via magnitude spectrale)\n",
    "FOURIER CNNs (Rippel et al., 2015)\n",
    "→ montre qu'une représentation FFT est plus stable et expressive que pixels bruts.\n",
    "Spectral Representations for Image Classification (several IEEE papers)\n",
    "→ radial power spectra suffisent à classifier des textures complexes.\n",
    "Why Do Deep Neural Networks Learn High-Frequency Patterns?\n",
    "(Xu et al., NeurIPS 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "13b8e64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', class_weight='balanced', random_state=0)\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_val_pred = svm_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "eca6138b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.57      0.67        97\n",
      "           1       0.15      0.19      0.17        26\n",
      "           2       0.27      0.22      0.24        41\n",
      "           3       0.50      0.23      0.32        39\n",
      "           4       0.16      0.77      0.26        13\n",
      "\n",
      "    accuracy                           0.41       216\n",
      "   macro avg       0.38      0.40      0.33       216\n",
      "weighted avg       0.53      0.41      0.44       216\n",
      "\n",
      "Balanced acc : 0.3957660393415988\n",
      "Recall par classe : [0.56701031 0.19230769 0.2195122  0.23076923 0.76923077]\n",
      "Recall moyen : 0.3957660393415988\n",
      "[[55 15 10  5 12]\n",
      " [ 2  5  6  1 12]\n",
      " [ 5  6  9  3 18]\n",
      " [ 5  6  7  9 12]\n",
      " [ 1  1  1  0 10]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "#y_pred_val = model.predict(X_val)\n",
    "#acc = (y_pred_val == y_val).mean()\n",
    "#print(\"Test accuracy =\", acc)\n",
    "\n",
    "cm = confusion_matrix(y_val, y_val_pred)\n",
    "bal_acc = balanced_accuracy(y_val, y_val_pred)\n",
    "rec = recall_per_class(cm)\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "print(\"Balanced acc :\", bal_acc)\n",
    "print(\"Recall par classe :\", rec)\n",
    "print(\"Recall moyen :\", rec.mean())\n",
    "print(cm)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "5399f043",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pkg = {\n",
    "    'model': model, \n",
    "    'scaler': scaler, \n",
    "    'train_min': train_min,\n",
    "    'train_max':train_max,\n",
    "    'train_mean': train_mean,\n",
    "    'train_std': train_std\n",
    "}\n",
    "\n",
    "pickle.dump(model_pkg, open(\"model_perceptron.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "934faf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier 'submission.csv' généré !\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# --------------------------\n",
    "# 1. Charger le modèle entraîné\n",
    "# --------------------------\n",
    "model_pkg_pred = pickle.load(open(\"model_perceptron.pkl\", \"rb\"))\n",
    "model= model_pkg_pred['model']\n",
    "scaler = model_pkg_pred['scaler']\n",
    "train_min = model_pkg_pred['train_min']\n",
    "train_max = model_pkg_pred['train_max']\n",
    "train_mean = model_pkg_pred['train_mean']\n",
    "train_std = model_pkg_pred['train_std']\n",
    "\n",
    "# --------------------------\n",
    "# 2. Charger le test_data.pkl\n",
    "# --------------------------\n",
    "with open(\"ift-3395-6390-kaggle-2-competition-fall-2025/test_data.pkl\", \"rb\") as f:\n",
    "    test_data = pickle.load(f)\n",
    "\n",
    "X_test_imgs = test_data[\"images\"].astype(np.float32)\n",
    "\n",
    "X_test_imgs = (X_test_imgs - train_min) / (train_max - train_min + 1e-6)\n",
    "#X_test_imgs = (X_test_imgs - train_mean) / (train_std + 1e-6)\n",
    "\n",
    "# --------------------------\n",
    "# 4. Normaliser avec les stats du train\n",
    "# --------------------------\n",
    "fft_mag_test = fft_features(X_test_imgs)\n",
    "X_fft_test = np.array([radial_profile(img) for img in fft_mag_test], dtype=np.float32)\n",
    "X_stats_test = np.array([extract_simple_stats(img) for img in X_test_imgs], dtype=np.float32)\n",
    "X_color_test = np.array([extract_channel_stats(img) for img in X_test_imgs], dtype=np.float32)\n",
    "X_hsv_test = np.array([extract_hsv_stats(img) for img in X_test_imgs], dtype=np.float32)\n",
    "X_sobel_test = np.array([extract_sobel_features(img) for img in X_test_imgs], dtype=np.float32)\n",
    "X_test = np.hstack([X_fft_test, X_stats_test, X_color_test])\n",
    "\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# --------------------------\n",
    "# 5. Prédire\n",
    "# --------------------------\n",
    "\n",
    "y_pred = model.predict(X_test).astype(int)\n",
    "\n",
    "# --------------------------\n",
    "# 6. Générer le CSV Kaggle\n",
    "# --------------------------\n",
    "df = pd.DataFrame({\n",
    "    \"ID\": np.arange(1, len(y_pred)+1),\n",
    "    \"Label\": y_pred\n",
    "})\n",
    "\n",
    "df.to_csv(\"ift3395_YAPS_MCS_V21.csv\", index=False)\n",
    "\n",
    "print(\"Fichier 'submission.csv' généré !\")\n",
    "\n",
    "#print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "dec6f1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Label      \n",
      "     self other\n",
      "1     0.0   3.0\n",
      "6     0.0   4.0\n",
      "10    0.0   4.0\n",
      "13    0.0   3.0\n",
      "17    0.0   3.0\n",
      "..    ...   ...\n",
      "386   0.0   2.0\n",
      "388   0.0   3.0\n",
      "391   0.0   3.0\n",
      "393   0.0   4.0\n",
      "397   0.0   1.0\n",
      "\n",
      "[208 rows x 2 columns]\n",
      "Nombre de différences : 208\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df1 = pd.read_csv(\"ift3395_YAPS_MCS_V21.csv\")\n",
    "df2 = pd.read_csv(\"ift3395_YAPS_MCS_V19._Ref.csv\")\n",
    "\n",
    "comparison = df1.compare(df2)\n",
    "print(comparison)\n",
    "print(\"Nombre de différences :\", len(comparison))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle2 (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
