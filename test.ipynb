{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa3270e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device utilisé : mps\n",
      "Chargement des données...\n",
      "Stats -> Mean: ['0.211', '0.005', '0.229'], Std: ['0.189', '0.017', '0.170']\n",
      "Distribution: {np.uint8(0): np.int64(486), np.uint8(1): np.int64(128), np.uint8(2): np.int64(206), np.uint8(3): np.int64(194), np.uint8(4): np.int64(66)}\n",
      "\n",
      "============================================================\n",
      "FOLD 1/5\n",
      "============================================================\n",
      "Train: 864 | Val: 216\n",
      "Train dist: {np.uint8(0): np.int64(388), np.uint8(1): np.int64(103), np.uint8(2): np.int64(165), np.uint8(3): np.int64(155), np.uint8(4): np.int64(53)}\n",
      "Epoch 01 | Train: 1.713 | Val: 23.382 | Acc: 0.454 | Bal Acc: 0.2000\n",
      "Epoch 05 | Train: 1.536 | Val: 1.673 | Acc: 0.171 | Bal Acc: 0.2476\n",
      "Epoch 10 | Train: 1.515 | Val: 1.718 | Acc: 0.282 | Bal Acc: 0.2746\n",
      "✓ Sauvegarde | Bal Acc: 0.3616 | Class 4 Recall: 0.92\n",
      "Epoch 15 | Train: 1.511 | Val: 1.627 | Acc: 0.250 | Bal Acc: 0.3643\n",
      "✓ Sauvegarde | Bal Acc: 0.3643 | Class 4 Recall: 0.85\n",
      "✓ Sauvegarde | Bal Acc: 0.3696 | Class 4 Recall: 0.92\n",
      "Epoch 20 | Train: 1.507 | Val: 1.639 | Acc: 0.208 | Bal Acc: 0.3175\n",
      "✓ Sauvegarde | Bal Acc: 0.3798 | Class 4 Recall: 0.92\n",
      "Epoch 25 | Train: 1.507 | Val: 1.614 | Acc: 0.250 | Bal Acc: 0.3597\n",
      "Epoch 30 | Train: 1.504 | Val: 1.607 | Acc: 0.227 | Bal Acc: 0.3376\n",
      "Early stopping à epoch 34\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "RÉSULTATS FOLD 1\n",
      "────────────────────────────────────────────────────────────\n",
      "Balanced Accuracy: 0.3798\n",
      "Accuracy: 0.2685\n",
      "\n",
      "Per-Class Recall:\n",
      "  Classe 0: 0.296\n",
      "  Classe 1: 0.680\n",
      "  Classe 2: 0.000\n",
      "  Classe 3: 0.000\n",
      "  Classe 4: 0.923\n",
      "\n",
      "============================================================\n",
      "FOLD 2/5\n",
      "============================================================\n",
      "Train: 864 | Val: 216\n",
      "Train dist: {np.uint8(0): np.int64(389), np.uint8(1): np.int64(103), np.uint8(2): np.int64(164), np.uint8(3): np.int64(156), np.uint8(4): np.int64(52)}\n",
      "Epoch 01 | Train: 1.660 | Val: 2.184 | Acc: 0.106 | Bal Acc: 0.1681\n",
      "Epoch 05 | Train: 1.549 | Val: 1.776 | Acc: 0.088 | Bal Acc: 0.1838\n",
      "Epoch 10 | Train: 1.505 | Val: 1.702 | Acc: 0.176 | Bal Acc: 0.2785\n",
      "Early stopping à epoch 12\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "RÉSULTATS FOLD 2\n",
      "────────────────────────────────────────────────────────────\n",
      "Balanced Accuracy: 0.3433\n",
      "Accuracy: 0.2963\n",
      "\n",
      "Per-Class Recall:\n",
      "  Classe 0: 0.402\n",
      "  Classe 1: 0.600\n",
      "  Classe 2: 0.000\n",
      "  Classe 3: 0.000\n",
      "  Classe 4: 0.714\n",
      "\n",
      "============================================================\n",
      "FOLD 3/5\n",
      "============================================================\n",
      "Train: 864 | Val: 216\n",
      "Train dist: {np.uint8(0): np.int64(389), np.uint8(1): np.int64(102), np.uint8(2): np.int64(165), np.uint8(3): np.int64(155), np.uint8(4): np.int64(53)}\n",
      "Epoch 01 | Train: 1.676 | Val: 2.081 | Acc: 0.130 | Bal Acc: 0.2282\n",
      "Epoch 05 | Train: 1.544 | Val: 1.691 | Acc: 0.222 | Bal Acc: 0.3003\n",
      "Epoch 10 | Train: 1.584 | Val: 1.616 | Acc: 0.282 | Bal Acc: 0.3102\n",
      "Epoch 15 | Train: 1.495 | Val: 1.617 | Acc: 0.231 | Bal Acc: 0.3003\n",
      "Early stopping à epoch 16\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "RÉSULTATS FOLD 3\n",
      "────────────────────────────────────────────────────────────\n",
      "Balanced Accuracy: 0.3195\n",
      "Accuracy: 0.1389\n",
      "\n",
      "Per-Class Recall:\n",
      "  Classe 0: 0.010\n",
      "  Classe 1: 0.538\n",
      "  Classe 2: 0.049\n",
      "  Classe 3: 0.000\n",
      "  Classe 4: 1.000\n",
      "\n",
      "============================================================\n",
      "FOLD 4/5\n",
      "============================================================\n",
      "Train: 864 | Val: 216\n",
      "Train dist: {np.uint8(0): np.int64(389), np.uint8(1): np.int64(102), np.uint8(2): np.int64(165), np.uint8(3): np.int64(155), np.uint8(4): np.int64(53)}\n",
      "Epoch 01 | Train: 1.677 | Val: 14.225 | Acc: 0.449 | Bal Acc: 0.2000\n",
      "Epoch 05 | Train: 1.525 | Val: 1.743 | Acc: 0.130 | Bal Acc: 0.2487\n",
      "Epoch 10 | Train: 1.537 | Val: 1.807 | Acc: 0.083 | Bal Acc: 0.2256\n",
      "✓ Sauvegarde | Bal Acc: 0.3502 | Class 4 Recall: 0.69\n",
      "Epoch 15 | Train: 1.496 | Val: 1.788 | Acc: 0.079 | Bal Acc: 0.2231\n",
      "Epoch 20 | Train: 1.506 | Val: 1.607 | Acc: 0.296 | Bal Acc: 0.3552\n",
      "✓ Sauvegarde | Bal Acc: 0.3552 | Class 4 Recall: 0.69\n",
      "Epoch 25 | Train: 1.518 | Val: 1.621 | Acc: 0.269 | Bal Acc: 0.3280\n",
      "✓ Sauvegarde | Bal Acc: 0.3552 | Class 4 Recall: 0.92\n",
      "Epoch 30 | Train: 1.534 | Val: 1.625 | Acc: 0.273 | Bal Acc: 0.3532\n",
      "✓ Sauvegarde | Bal Acc: 0.3603 | Class 4 Recall: 0.92\n",
      "Epoch 35 | Train: 1.522 | Val: 1.620 | Acc: 0.273 | Bal Acc: 0.3398\n",
      "Epoch 40 | Train: 1.483 | Val: 1.618 | Acc: 0.273 | Bal Acc: 0.3398\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "RÉSULTATS FOLD 4\n",
      "────────────────────────────────────────────────────────────\n",
      "Balanced Accuracy: 0.3603\n",
      "Accuracy: 0.2824\n",
      "\n",
      "Per-Class Recall:\n",
      "  Classe 0: 0.340\n",
      "  Classe 1: 0.385\n",
      "  Classe 2: 0.000\n",
      "  Classe 3: 0.154\n",
      "  Classe 4: 0.923\n",
      "\n",
      "============================================================\n",
      "FOLD 5/5\n",
      "============================================================\n",
      "Train: 864 | Val: 216\n",
      "Train dist: {np.uint8(0): np.int64(389), np.uint8(1): np.int64(102), np.uint8(2): np.int64(165), np.uint8(3): np.int64(155), np.uint8(4): np.int64(53)}\n",
      "Epoch 01 | Train: 1.663 | Val: 15.522 | Acc: 0.444 | Bal Acc: 0.2205\n",
      "Epoch 05 | Train: 1.553 | Val: 1.774 | Acc: 0.083 | Bal Acc: 0.2077\n",
      "Epoch 10 | Train: 1.554 | Val: 1.667 | Acc: 0.264 | Bal Acc: 0.2789\n",
      "✓ Sauvegarde | Bal Acc: 0.3289 | Class 4 Recall: 0.77\n",
      "Epoch 15 | Train: 1.543 | Val: 1.663 | Acc: 0.213 | Bal Acc: 0.3105\n",
      "✓ Sauvegarde | Bal Acc: 0.3340 | Class 4 Recall: 0.77\n",
      "✓ Sauvegarde | Bal Acc: 0.3387 | Class 4 Recall: 0.85\n",
      "Epoch 20 | Train: 1.526 | Val: 1.649 | Acc: 0.213 | Bal Acc: 0.3335\n",
      "Epoch 25 | Train: 1.473 | Val: 1.646 | Acc: 0.204 | Bal Acc: 0.3351\n",
      "Early stopping à epoch 28\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "RÉSULTATS FOLD 5\n",
      "────────────────────────────────────────────────────────────\n",
      "Balanced Accuracy: 0.3387\n",
      "Accuracy: 0.2222\n",
      "\n",
      "Per-Class Recall:\n",
      "  Classe 0: 0.206\n",
      "  Classe 1: 0.615\n",
      "  Classe 2: 0.000\n",
      "  Classe 3: 0.026\n",
      "  Classe 4: 0.846\n",
      "\n",
      "============================================================\n",
      "RÉSUMÉ CROSS-VALIDATION\n",
      "============================================================\n",
      "Balanced Accuracy moyenne: 0.3483 ± 0.0204\n",
      "Scores par fold: ['0.3798', '0.3433', '0.3195', '0.3603', '0.3387']\n",
      "\n",
      "Recall moyen par classe:\n",
      "  Classe 0: 0.251 ± 0.136\n",
      "  Classe 1: 0.564 ± 0.100\n",
      "  Classe 2: 0.010 ± 0.020\n",
      "  Classe 3: 0.036 ± 0.060\n",
      "  Classe 4: 0.881 ± 0.097\n",
      "\n",
      "============================================================\n",
      "GÉNÉRATION SOUMISSION (Ensemble + TTA)\n",
      "============================================================\n",
      "✓ Fichier 'submission_ensemble_kfold.csv' généré!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report\n",
    "from collections import defaultdict\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION GLOBALE\n",
    "# ==========================================\n",
    "SEED = 42\n",
    "N_SPLITS = 5\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS_PER_FOLD = 50\n",
    "LEARNING_RATE = 1e-3  # CORRIGÉ: Réduit pour Adam\n",
    "WEIGHT_DECAY = 1e-4   # CORRIGÉ: Moins agressif\n",
    "EARLY_STOP_PATIENCE = 15\n",
    "DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    if torch.backends.mps.is_available():\n",
    "        torch.mps.manual_seed(seed)\n",
    "\n",
    "set_seed(SEED)\n",
    "print(f\"Device utilisé : {DEVICE}\\n\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. PRÉ-TRAITEMENT & DATASET\n",
    "# ==========================================\n",
    "def enhance_channels(img_tensor):\n",
    "    r = img_tensor[0]\n",
    "    b = img_tensor[2]\n",
    "    diff = (r - b) + 0.5\n",
    "    diff = torch.clamp(diff, 0, 1)\n",
    "    return torch.stack([r, diff, b], dim=0)\n",
    "\n",
    "class RetinaDataset(Dataset):\n",
    "    def __init__(self, images, labels=None, transform=None, is_test=False):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_arr = self.images[idx]\n",
    "        img_pil = Image.fromarray(img_arr.astype('uint8'))\n",
    "        \n",
    "        if self.transform:\n",
    "            img_tensor = self.transform(img_pil)\n",
    "        else:\n",
    "            img_tensor = transforms.ToTensor()(img_pil)\n",
    "            \n",
    "        if self.is_test:\n",
    "            return img_tensor\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        if hasattr(label, 'item'):\n",
    "            label = int(label.item())\n",
    "        else:\n",
    "            label = int(label)\n",
    "            \n",
    "        return img_tensor, label\n",
    "\n",
    "# ==========================================\n",
    "# 3. ARCHITECTURE SIMPLIFIÉE\n",
    "# ==========================================\n",
    "class SimpleNet(nn.Module):\n",
    "    \"\"\"Architecture plus simple et stable\"\"\"\n",
    "    def __init__(self, num_classes=5):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Bloc 1 (28x28 -> 14x14)\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        # Bloc 2 (14x14 -> 7x7)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # Bloc 3 (7x7 -> 3x3)\n",
    "        self.conv5 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # Global Average Pooling\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        # Classifier\n",
    "        self.fc1 = nn.Linear(128, 128)\n",
    "        self.dropout = nn.Dropout(0.3)  # RÉDUIT\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        \n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.BatchNorm1d)):\n",
    "                init.constant_(m.weight, 1)\n",
    "                init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init.kaiming_normal_(m.weight)\n",
    "                init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Bloc 1\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        # Bloc 2\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        # Bloc 3\n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        # GAP + Classifier\n",
    "        x = self.gap(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# ==========================================\n",
    "# 4. PRÉPARATION DES DONNÉES\n",
    "# ==========================================\n",
    "print(\"Chargement des données...\")\n",
    "TRAIN_PATH = \"ift-3395-6390-kaggle-2-competition-fall-2025/train_data.pkl\" \n",
    "TEST_PATH = \"ift-3395-6390-kaggle-2-competition-fall-2025/test_data.pkl\"\n",
    "\n",
    "with open(TRAIN_PATH, \"rb\") as f:\n",
    "    train_data_raw = pickle.load(f)\n",
    "\n",
    "X_all = train_data_raw[\"images\"].astype(np.float32)\n",
    "y_all = train_data_raw[\"labels\"].reshape(-1)\n",
    "\n",
    "# Stats globales\n",
    "X_tmp = X_all / 255.0\n",
    "IR_MEAN = X_tmp.mean(axis=(0, 1, 2)).tolist()\n",
    "IR_STD = X_tmp.std(axis=(0, 1, 2)).tolist()\n",
    "print(f\"Stats -> Mean: {[f'{m:.3f}' for m in IR_MEAN]}, Std: {[f'{s:.3f}' for s in IR_STD]}\")\n",
    "\n",
    "unique, counts = np.unique(y_all, return_counts=True)\n",
    "print(f\"Distribution: {dict(zip(unique, counts))}\\n\")\n",
    "\n",
    "# TRANSFORMS MODÉRÉS (clé du succès)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.RandomVerticalFlip(0.5),\n",
    "    transforms.RandomRotation(15),  # RÉDUIT: 15° au lieu de 90°\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(enhance_channels),\n",
    "    transforms.Normalize(IR_MEAN, IR_STD)\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(enhance_channels),\n",
    "    transforms.Normalize(IR_MEAN, IR_STD)\n",
    "])\n",
    "\n",
    "# ==========================================\n",
    "# 5. BOUCLE CROSS-VALIDATION\n",
    "# ==========================================\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "fold_scores = []\n",
    "fold_reports = []\n",
    "model_paths = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_all, y_all)):\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"FOLD {fold+1}/{N_SPLITS}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    X_train, y_train = X_all[train_idx], y_all[train_idx]\n",
    "    X_val, y_val = X_all[val_idx], y_all[val_idx]\n",
    "    \n",
    "    print(f\"Train: {len(X_train)} | Val: {len(X_val)}\")\n",
    "    \n",
    "    train_ds = RetinaDataset(X_train, y_train, transform=train_transform)\n",
    "    val_ds = RetinaDataset(X_val, y_val, transform=val_transform)\n",
    "    \n",
    "    # SIMPLE DATALOADERS (PAS de sampler complexe)\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # Modèle simplifié\n",
    "    model = SimpleNet(num_classes=5).to(DEVICE)\n",
    "    \n",
    "    # Optimizer simple\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    \n",
    "    # Scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', factor=0.5, patience=7, min_lr=1e-6, verbose=False\n",
    "    )\n",
    "    \n",
    "    # LOSS AVEC CLASS WEIGHTS UNIQUEMENT (pas de label smoothing au début)\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "    loss_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "    criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor(loss_weights).to(DEVICE))\n",
    "    \n",
    "    # Training\n",
    "    best_bal_acc = 0.0\n",
    "    best_model_name = f\"model_fold_{fold}.pth\"\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(EPOCHS_PER_FOLD):\n",
    "        # TRAIN\n",
    "        model.train()\n",
    "        train_loss, train_correct, train_total = 0, 0, 0\n",
    "        for imgs, lbls in train_loader:\n",
    "            imgs, lbls = imgs.to(DEVICE), lbls.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, lbls)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # RÉDUIT\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += (preds == lbls).sum().item()\n",
    "            train_total += lbls.size(0)\n",
    "        \n",
    "        # VALIDATION\n",
    "        model.eval()\n",
    "        all_preds, all_targets = [], []\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, lbls in val_loader:\n",
    "                imgs, lbls = imgs.to(DEVICE), lbls.to(DEVICE)\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, lbls)\n",
    "                val_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_targets.extend(lbls.cpu().numpy())\n",
    "        \n",
    "        avg_train = train_loss / len(train_loader)\n",
    "        avg_val = val_loss / len(val_loader)\n",
    "        train_acc = train_correct / train_total\n",
    "        val_bal_acc = balanced_accuracy_score(all_targets, all_preds)\n",
    "        val_acc = accuracy_score(all_targets, all_preds)\n",
    "        \n",
    "        # Print\n",
    "        if (epoch+1) % 5 == 0 or epoch == 0:\n",
    "            print(f\"Epoch {epoch+1:02d} | TrLoss: {avg_train:.3f} TrainAcc: {train_acc:.3f} | \"\n",
    "                  f\"ValLoss: {avg_val:.3f} ValAcc: {val_acc:.3f} BalAcc: {val_bal_acc:.4f}\")\n",
    "        \n",
    "        scheduler.step(val_bal_acc)\n",
    "        \n",
    "        # Save best\n",
    "        if val_bal_acc > best_bal_acc:\n",
    "            best_bal_acc = val_bal_acc\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), best_model_name)\n",
    "            \n",
    "            if epoch >= 10:\n",
    "                report = classification_report(all_targets, all_preds, output_dict=True, zero_division=0)\n",
    "                print(f\"  ✓ Meilleur | BalAcc: {best_bal_acc:.4f} | \"\n",
    "                      f\"C4 Recall: {report.get('4', {}).get('recall', 0):.2f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= EARLY_STOP_PATIENCE:\n",
    "                print(f\"  Early stop @ epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    # Évaluation finale\n",
    "    model.load_state_dict(torch.load(best_model_name, map_location=DEVICE))\n",
    "    model.eval()\n",
    "    all_preds, all_targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in val_loader:\n",
    "            imgs, lbls = imgs.to(DEVICE), lbls.to(DEVICE)\n",
    "            outputs = model(imgs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(lbls.cpu().numpy())\n",
    "    \n",
    "    final_report = classification_report(all_targets, all_preds, output_dict=True, zero_division=0)\n",
    "    \n",
    "    print(f\"\\n{'─'*60}\")\n",
    "    print(f\"FOLD {fold+1} FINAL\")\n",
    "    print(f\"{'─'*60}\")\n",
    "    print(f\"Balanced Acc: {best_bal_acc:.4f} | Accuracy: {accuracy_score(all_targets, all_preds):.4f}\")\n",
    "    print(\"Per-Class Recall:\")\n",
    "    for cls in range(5):\n",
    "        recall = final_report.get(str(cls), {}).get('recall', 0)\n",
    "        support = final_report.get(str(cls), {}).get('support', 0)\n",
    "        print(f\"  Class {cls}: {recall:.3f} (n={int(support)})\")\n",
    "    print()\n",
    "    \n",
    "    fold_scores.append(best_bal_acc)\n",
    "    fold_reports.append(final_report)\n",
    "    model_paths.append(best_model_name)\n",
    "    \n",
    "    del model\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# ==========================================\n",
    "# RÉSUMÉ CV\n",
    "# ==========================================\n",
    "print(f\"{'='*60}\")\n",
    "print(\"RÉSUMÉ CROSS-VALIDATION\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Balanced Acc: {np.mean(fold_scores):.4f} ± {np.std(fold_scores):.4f}\")\n",
    "print(f\"Scores: {[f'{s:.4f}' for s in fold_scores]}\\n\")\n",
    "\n",
    "avg_recalls = defaultdict(list)\n",
    "for report in fold_reports:\n",
    "    for cls in range(5):\n",
    "        recall = report.get(str(cls), {}).get('recall', 0)\n",
    "        avg_recalls[cls].append(recall)\n",
    "\n",
    "print(\"Recall moyen par classe:\")\n",
    "for cls in range(5):\n",
    "    recalls = avg_recalls[cls]\n",
    "    print(f\"  Classe {cls}: {np.mean(recalls):.3f} ± {np.std(recalls):.3f}\")\n",
    "\n",
    "# ==========================================\n",
    "# 6. INFERENCE\n",
    "# ==========================================\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"GÉNÉRATION SOUMISSION\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "with open(TEST_PATH, \"rb\") as f:\n",
    "    test_data = pickle.load(f)\n",
    "\n",
    "test_ds = RetinaDataset(test_data['images'], labels=None, transform=val_transform, is_test=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "models = []\n",
    "for path in model_paths:\n",
    "    m = SimpleNet(num_classes=5).to(DEVICE)\n",
    "    m.load_state_dict(torch.load(path, map_location=DEVICE))\n",
    "    m.eval()\n",
    "    models.append(m)\n",
    "\n",
    "final_preds = []\n",
    "with torch.no_grad():\n",
    "    for imgs in test_loader:\n",
    "        imgs = imgs.to(DEVICE)\n",
    "        ensemble_logits = torch.zeros(imgs.size(0), 5).to(DEVICE)\n",
    "        \n",
    "        for m in models:\n",
    "            # TTA: Normal + Flip H\n",
    "            out_norm = m(imgs)\n",
    "            out_h = m(torch.flip(imgs, [3]))\n",
    "            ensemble_logits += (out_norm + out_h) / 2.0\n",
    "        \n",
    "        ensemble_logits /= len(models)\n",
    "        _, predicted = torch.max(ensemble_logits, 1)\n",
    "        final_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "df = pd.DataFrame({\"ID\": np.arange(1, len(final_preds) + 1), \"Label\": final_preds})\n",
    "df.to_csv(\"submission_ensemble_kfold.csv\", index=False)\n",
    "print(\"✓ Fichier 'submission_ensemble_kfold.csv' généré!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle2 (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
